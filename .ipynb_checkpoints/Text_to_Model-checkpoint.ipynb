{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile all .txt file data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all the files I want to grab\n",
    "cleantxt_list = glob.glob(\"Austin_Transcripts/*_c.txt\")\n",
    "\n",
    "# initiate a dictionary\n",
    "text_dict = {}\n",
    "\n",
    "# compile df - Jeremy magic\n",
    "date_list, text_list = list(), list()\n",
    "for filename in cleantxt_list:\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.read()\n",
    "    date = filename.split(\"/\")[1][:-6]\n",
    "    for element in data.split('_'):\n",
    "        text_list.append(element)\n",
    "        date_list.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dict = {'date': date_list, 'text': text_list}\n",
    "df = pd.DataFrame(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text\n",
       "0  2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...\n",
       "1  2015-03-26   There are 20 that are signed up for the next ...\n",
       "2  2015-03-26   Okay The other thing is Im going to do everyt...\n",
       "3  2015-03-26   Thanks Hello My name is Jacquie benastante an...\n",
       "4  2015-03-26   Good afternoon Three of us are here today and..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"speakers_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokeninze text column\n",
    "df['tokenized_sents'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "      <td>[Mayor, pro, tem, I, had, a, que, stion, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "      <td>[There, are, 20, that, are, signed, up, for, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "      <td>[Okay, The, other, thing, is, Im, going, to, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "      <td>[Thanks, Hello, My, name, is, Jacquie, benasta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "      <td>[Good, afternoon, Three, of, us, are, here, to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...   \n",
       "1  2015-03-26   There are 20 that are signed up for the next ...   \n",
       "2  2015-03-26   Okay The other thing is Im going to do everyt...   \n",
       "3  2015-03-26   Thanks Hello My name is Jacquie benastante an...   \n",
       "4  2015-03-26   Good afternoon Three of us are here today and...   \n",
       "\n",
       "                                     tokenized_sents  \n",
       "0  [Mayor, pro, tem, I, had, a, que, stion, for, ...  \n",
       "1  [There, are, 20, that, are, signed, up, for, t...  \n",
       "2  [Okay, The, other, thing, is, Im, going, to, d...  \n",
       "3  [Thanks, Hello, My, name, is, Jacquie, benasta...  \n",
       "4  [Good, afternoon, Three, of, us, are, here, to...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "emb_model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(list): \n",
    "  #For word in list, get embedding, return all words in list\"\"\"\n",
    "  vectors = []\n",
    "  for word in list: \n",
    "    try:\n",
    "      vector = emb_model[word]\n",
    "      vectors.append(vector)\n",
    "\n",
    "    except KeyError: \n",
    "      pass\n",
    "\n",
    "  return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vectors'] = df[\"tokenized_sents\"].apply(get_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "      <td>[Mayor, pro, tem, I, had, a, que, stion, for, ...</td>\n",
       "      <td>[[-0.07763672, -0.12792969, 0.103515625, -0.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "      <td>[There, are, 20, that, are, signed, up, for, t...</td>\n",
       "      <td>[[-0.111328125, 0.14355469, 0.18945312, -0.161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "      <td>[Okay, The, other, thing, is, Im, going, to, d...</td>\n",
       "      <td>[[0.09375, -0.07470703, 0.2109375, 0.22167969,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "      <td>[Thanks, Hello, My, name, is, Jacquie, benasta...</td>\n",
       "      <td>[[-0.3046875, 0.20703125, -0.00390625, 0.16503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "      <td>[Good, afternoon, Three, of, us, are, here, to...</td>\n",
       "      <td>[[-0.10888672, -0.07470703, -0.045410156, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...   \n",
       "1  2015-03-26   There are 20 that are signed up for the next ...   \n",
       "2  2015-03-26   Okay The other thing is Im going to do everyt...   \n",
       "3  2015-03-26   Thanks Hello My name is Jacquie benastante an...   \n",
       "4  2015-03-26   Good afternoon Three of us are here today and...   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  [Mayor, pro, tem, I, had, a, que, stion, for, ...   \n",
       "1  [There, are, 20, that, are, signed, up, for, t...   \n",
       "2  [Okay, The, other, thing, is, Im, going, to, d...   \n",
       "3  [Thanks, Hello, My, name, is, Jacquie, benasta...   \n",
       "4  [Good, afternoon, Three, of, us, are, here, to...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [[-0.07763672, -0.12792969, 0.103515625, -0.33...  \n",
       "1  [[-0.111328125, 0.14355469, 0.18945312, -0.161...  \n",
       "2  [[0.09375, -0.07470703, 0.2109375, 0.22167969,...  \n",
       "3  [[-0.3046875, 0.20703125, -0.00390625, 0.16503...  \n",
       "4  [[-0.10888672, -0.07470703, -0.045410156, -0.0...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [[-0.07763672, -0.12792969, 0.103515625, -0.33...\n",
       "1       [[-0.111328125, 0.14355469, 0.18945312, -0.161...\n",
       "2       [[0.09375, -0.07470703, 0.2109375, 0.22167969,...\n",
       "3       [[-0.3046875, 0.20703125, -0.00390625, 0.16503...\n",
       "4       [[-0.10888672, -0.07470703, -0.045410156, -0.0...\n",
       "5       [[-0.22558594, 0.13085938, -0.16308594, 0.1181...\n",
       "6       [[-0.20605469, -0.12695312, 0.12890625, 0.2539...\n",
       "7       [[-0.015380859, 0.17773438, -0.12597656, -0.09...\n",
       "8       [[-0.109375, 0.11230469, 0.19140625, 0.078125,...\n",
       "9       [[-0.20605469, -0.12695312, 0.12890625, 0.2539...\n",
       "10      [[-0.20605469, -0.12695312, 0.12890625, 0.2539...\n",
       "11      [[0.09375, -0.07470703, 0.2109375, 0.22167969,...\n",
       "12      [[0.07861328, 0.13183594, 0.18945312, 0.314453...\n",
       "13      [[-0.10888672, -0.07470703, -0.045410156, -0.0...\n",
       "14      [[-0.1796875, 0.18652344, 0.00089645386, -0.06...\n",
       "15      [[-0.07763672, -0.12792969, 0.103515625, -0.33...\n",
       "16      [[-0.10888672, -0.07470703, -0.045410156, -0.0...\n",
       "17      [[-0.16210938, 0.08691406, 0.20117188, 0.04248...\n",
       "18      [[-0.053466797, 0.13085938, 0.265625, 0.208984...\n",
       "19      [[-0.07763672, -0.12792969, 0.103515625, -0.33...\n",
       "20      [[-0.10888672, -0.07470703, -0.045410156, -0.0...\n",
       "21      [[-0.053955078, -0.01361084, -0.20410156, -0.0...\n",
       "22      [[-0.22558594, 0.13085938, -0.16308594, 0.1181...\n",
       "23      [[-0.1796875, 0.18652344, 0.00089645386, -0.06...\n",
       "24      [[-0.20605469, -0.12695312, 0.12890625, 0.2539...\n",
       "25      [[0.07910156, -0.0050354004, 0.111816406, 0.21...\n",
       "26      [[-0.10888672, -0.07470703, -0.045410156, -0.0...\n",
       "27      [[-0.20117188, -0.07128906, 0.068847656, -0.03...\n",
       "28      [[-0.088378906, -0.011962891, 0.21484375, 0.05...\n",
       "29      [[-0.07763672, -0.12792969, 0.103515625, -0.33...\n",
       "                              ...                        \n",
       "9885    [[0.032226562, 0.12207031, 0.22558594, -0.1289...\n",
       "9886    [[-0.07763672, -0.12792969, 0.103515625, -0.33...\n",
       "9887    [[-0.053466797, 0.13085938, 0.265625, 0.208984...\n",
       "9888    [[0.053222656, -0.0065307617, 0.17578125, 0.12...\n",
       "9889    [[0.007751465, -0.088378906, 0.17675781, -0.02...\n",
       "9890    [[0.14257812, 0.037353516, 0.020751953, 0.3847...\n",
       "9891    [[-0.09863281, 0.0546875, 0.18359375, 0.183593...\n",
       "9892    [[0.07910156, -0.0050354004, 0.111816406, 0.21...\n",
       "9893    [[-0.09863281, 0.0546875, 0.18359375, 0.183593...\n",
       "9894    [[-0.053466797, 0.13085938, 0.265625, 0.208984...\n",
       "9895    [[0.09375, -0.07470703, 0.2109375, 0.22167969,...\n",
       "9896    [[-0.3046875, 0.20703125, -0.00390625, 0.16503...\n",
       "9897    [[-0.033447266, 0.1796875, 0.107421875, 0.1083...\n",
       "9898    [[-0.033447266, 0.1796875, 0.107421875, 0.1083...\n",
       "9899    [[0.07910156, -0.0050354004, 0.111816406, 0.21...\n",
       "9900    [[0.01953125, 0.061279297, 0.002319336, 0.0295...\n",
       "9901    [[-0.09863281, 0.0546875, 0.18359375, 0.183593...\n",
       "9902    [[0.07910156, -0.0050354004, 0.111816406, 0.21...\n",
       "9903    [[-0.033447266, 0.1796875, 0.107421875, 0.1083...\n",
       "9904    [[0.07910156, -0.0050354004, 0.111816406, 0.21...\n",
       "9905    [[-0.20605469, -0.12695312, 0.12890625, 0.2539...\n",
       "9906    [[-0.13867188, 0.12597656, 0.32617188, 0.09960...\n",
       "9907    [[0.06982422, 0.0072021484, -0.35546875, -0.01...\n",
       "9908    [[0.07910156, -0.0050354004, 0.111816406, 0.21...\n",
       "9909    [[-0.2890625, 0.32617188, 0.18945312, 0.116699...\n",
       "9910    [[-0.2890625, 0.32617188, 0.18945312, 0.116699...\n",
       "9911    [[-0.13867188, 0.12597656, 0.32617188, 0.09960...\n",
       "9912    [[-0.2265625, 0.15332031, 0.08886719, 0.072265...\n",
       "9913    [[-0.03112793, -0.19042969, 0.037353516, -0.24...\n",
       "9914    [[-0.07763672, -0.12792969, 0.103515625, -0.33...\n",
       "Name: vectors, Length: 9915, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"vectors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"speakers_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
