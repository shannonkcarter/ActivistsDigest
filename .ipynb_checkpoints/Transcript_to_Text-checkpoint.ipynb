{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 \n",
    "import textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import nltk\n",
    "import glob\n",
    "#from glob import glob\n",
    "import os\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kathrynkundrod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kathrynkundrod/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture text from pdf files, a singular example\n",
    "https://medium.com/@rqaiserr/how-to-convert-pdfs-into-searchable-key-words-with-python-85aab86c544f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = \"Austin_Transcripts/scrape2/2015_01_29.pdf\"\n",
    "\n",
    "pdfFileObj = open(filename,'rb')\n",
    "\n",
    "#The pdfReader variable is a readable object that will be parsed\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "#discerning the number of pages will allow us to parse through all #the pages\n",
    "num_pages = pdfReader.numPages\n",
    "count = 0\n",
    "text = \"\"\n",
    "\n",
    "#The while loop will read each page\n",
    "while count < num_pages:\n",
    "    pageObj = pdfReader.getPage(count)\n",
    "    count +=1\n",
    "    text += pageObj.extractText()\n",
    "\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture text from pdf files, loop through all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'glob' files, i.e., make a list of all with the same desired attribute\n",
    "# in this case, all pdfs in the folder Austin_Transcripts\n",
    "filelist = glob.glob(\"Austin_Transcripts/*.pdf\")\n",
    "#filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileroot, fileext = os.path.splitext(pdffile)\n",
    "output_filename = fileroot+'.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each file in filelist...\n",
    "for pdffile in filelist:\n",
    "    \n",
    "    # Open the pdf file and make it a pdf object\n",
    "    pdfFileObj = open(pdffile,'rb')\n",
    "\n",
    "    # The pdfReader variable is a readable object that will be parsed\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "    # Discerning the number of pages will allow us to parse through all #the pages\n",
    "    num_pages = pdfReader.numPages\n",
    "    count = 0\n",
    "    text = \"\"\n",
    "\n",
    "    # This while loop will read each page\n",
    "    # The 'text' output is what we want to save for each pdf\n",
    "    while count < num_pages:\n",
    "        pageObj = pdfReader.getPage(count)\n",
    "        count +=1\n",
    "        text += pageObj.extractText()\n",
    "\n",
    "    # Create an output file and put \"text\" in there\n",
    "    file = open(output_filename, \"w\")\n",
    "    file.write(text)\n",
    "    fileroot, fileext = os.path.splitext(pdffile)\n",
    "    output_filename = fileroot+'.txt'\n",
    "    file.close()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text files, a singular example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the file before opening so it's easier to iterate on later\n",
    "text_ex =  \"Austin_Transcripts/2017_03_23.txt\"\n",
    "f = open(text_ex, 'r')\n",
    "\n",
    "# turns f file into a string\n",
    "content = f.read()\n",
    "#type(content)   # it's a string\n",
    "#print(content)  # see, it's a string\n",
    "\n",
    "# always close files after pulling out the \"content\" or whatever you want to avoid overwriting\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove time stamp\n",
    "text_cleaning = re.sub(\"[\\[].*?[\\]]\", \"\", content)\n",
    "\n",
    "# remove the new line instances\n",
    "text_cleaning = text_cleaning.replace(\"\\n\", \" \")\n",
    "\n",
    "# subbing repeated white space for a single space\n",
    "text_cleaning = re.sub('\\s\\s+', ' ', text_cleaning)\n",
    "\n",
    "# remove header\n",
    "text_cleaning = re.sub(r'.*====', '=', text_cleaning)\n",
    "\n",
    "# remove header and prayer - turns out many people say 'amen', so don't do this\n",
    "#text_cleaning[text_cleaning.find(' Amen. '):]\n",
    "\n",
    "# Remove all punctuation that is not \">\"\n",
    "remove = string.punctuation\n",
    "remove = remove.replace(\">\", \"\") # don't remove carats\n",
    "remove = remove.replace(\":\", \"\") # keep these too, which helps me see when CC members are speaking\n",
    "pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "text_cleaning = re.sub(pattern, \"\", text_cleaning) \n",
    "\n",
    "# remove prayer\n",
    "text_cleaning = text_cleaning.split(' Amen ', 1)[-1]\n",
    "\n",
    "# split by speakers - now I have a list of string, each string a new speaker\n",
    "speaker_strings = text_cleaning.split(\">>\")\n",
    "speaker_strings[10:20]\n",
    "#type(speaker_strings)\n",
    "\n",
    "## Now, remove strings said by a CCM or Mayor, i.e., those tagged with a name\n",
    "  \n",
    "# copy the list to a new list to not overwrite progress\n",
    "speaker_strings1 = speaker_strings  \n",
    "  \n",
    "# initializing substring\n",
    "# want this to be a string that IDs any alpha character + :\n",
    "subs = '\\w+:' \n",
    "  \n",
    "# using list comprehension to get string without substring  \n",
    "# I want to print all lists that DO NOT contain the substring\n",
    "#speaker_strings2 = [i for i in speaker_strings1 if not subs in i] \n",
    "speaker_strings2 = [string for string in speaker_strings1 if not re.search(subs, string)]\n",
    "\n",
    "speaker_strings2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>> Mayor Adler: Thank you Now were going to call the meeti ng to order Today is April 13 2017 It is 10:08 Were in the city council chambers here at city hall 3:01 west second street Austin Texas Council we have some changes and corrections The pulled items this morning on the consent agenda are item 9 10 and 19 We had to add 22 being pulled But I can read in those changes African American resources commission Marian Connor by councilmember Flanagan who also nominates the standards commission Michael king and also mechanical plumbing and solar board Bashir Hamad And one more Were approving the waiver residency requirement of section 2121 of the city code for the service of Bashir Mohammed on the mechanical plumbing and solar board There are nominees listed on here for the manager search committ ee Of course those will be relevant if in fact we pass item number 22 which is a board and commission  Im sorry which is item number 27 Why Okay So youre going to pull ahead number 22 Im sorry 27 Do you need item 22 Yes T hats the pull So were going to pull 22 and 27 You cant do them simultaneously Okay Well do it that way Were going to pull 9 10 19 and 22 I dont know if theres anything else to be pulled We do have people to speak on the consent agenda >> Mayor >> Mayor Adler: Yes >> My nominee for the city managers search advisory task force >> Mayor Adler: We pulled that We can add that in second >> Okay thank you >> Mayor Adler: Okay Is jive Keller here Is Jan Daniels here  Okay Mr Pen a do you want to speak on the consent agenda >> I do mayor 9 15 16 17 and 18 9 has been pulled >> Mayor is 14 pulled >> Mayor Adler: 14 is not pulled >> Can I start with that You mentioned 10 or is that exempt from  item number 10 >> Mayor Adler: 9 and 10 have been pulled I had you signed up for 15 16 17 and 18 >> Okay and 14 14 is the relocation assistance and authorizing the payment of relocation funds located at 1127 at 52nd street I know we have an exce ption department I know theres been'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaning[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Mayor Adler: 14 is not pulled ',\n",
       " ' Can I start with that You mentioned 10 or is that exempt from  item number 10 ',\n",
       " ' Mayor Adler: 9 and 10 have been pulled I had you signed up for 15 16 17 and 18 ',\n",
       " ' Okay and 14 14 is the relocation assistance and authorizing the payment of relocation funds located at 1127 at 52nd street I know we have an exce ption department I know theres been complaints I know well inspect the units for deficiencies and problematic issues I was wondering why this did not occur quicker I had a phone call last year about this property Unfortunately I was in the hospital again so I was not able to address it with you But in the future thats more pertinent and more efficient in listening to the complaints of the resident I understand that the owner has been cited or will be cited But thats not enough Number 15 is th e Austin community college increased funding for child care equality Any increase for child care equality is a no brainer Child  children  child needs health care and theyre not getting it A lot of people in east Austin A lot of children are not g etting top care at the childrens hospital Ive seen it They say call the mayor Thats your job You said number 16 Number 16 is just a increasing for the community network and Raul is the the executive director of the organization Called the communit y action network Thats money well spent for the community And again mayor Number 16 ',\n",
       " ' Mayor Adler: 17 and 18 ',\n",
       " ' 17 Okay yes 17 appropriating 170000 grant funds for the Austin shelter Always supportive of women and especially children who ar e at risk These children are at risk mayor council They need this funding for actually appropriate needs immediate needs So this is an appropriate  appropriate funding for the Austin children for women and children Ill always support them You sa id number 18 right Number 18 has to do with increased mentoring is a no brainer Former teacher at ACC Austin independent school district And I taught also juniors in college But mentoring is very important to get the kids back on tra ck on education and the last item mayor And allow me to  Usa today good article about homeless veterans in Austin Texas Coming to Austin because he said he knows for a fact that there are more than 5000 homeless veterans in Austin Texas FYI I like to work with you and your office on that if it would be okay ',\n",
       " ' Mayor Adler: That would be great Thank you ',\n",
       " ' Thank you sir ',\n",
       " ' Mayor Adler: Thank you David king to speak on items 14 and 27 Andy young is on deck ',\n",
       " ' Thank you mayor Council members Mayor did  were items 24 and 25 pulled ']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split by speakers - now I have a list of string, each string a new speaker\n",
    "speaker_strings = text_cleaning.split(\">>\")\n",
    "speaker_strings[10:20]\n",
    "#type(speaker_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' Mayor ',\n",
       " ' My nominee for the city managers search advisory task force ',\n",
       " ' Okay thank you ',\n",
       " ' I do mayor 9 15 16 17 and 18 9 has been pulled ',\n",
       " ' Mayor is 14 pulled ',\n",
       " ' Can I start with that You mentioned 10 or is that exempt from  item number 10 ',\n",
       " ' Okay and 14 14 is the relocation assistance and authorizing the payment of relocation funds located at 1127 at 52nd street I know we have an exce ption department I know theres been complaints I know well inspect the units for deficiencies and problematic issues I was wondering why this did not occur quicker I had a phone call last year about this property Unfortunately I was in the hospital again so I was not able to address it with you But in the future thats more pertinent and more efficient in listening to the complaints of the resident I understand that the owner has been cited or will be cited But thats not enough Number 15 is th e Austin community college increased funding for child care equality Any increase for child care equality is a no brainer Child  children  child needs health care and theyre not getting it A lot of people in east Austin A lot of children are not g etting top care at the childrens hospital Ive seen it They say call the mayor Thats your job You said number 16 Number 16 is just a increasing for the community network and Raul is the the executive director of the organization Called the communit y action network Thats money well spent for the community And again mayor Number 16 ',\n",
       " ' 17 Okay yes 17 appropriating 170000 grant funds for the Austin shelter Always supportive of women and especially children who ar e at risk These children are at risk mayor council They need this funding for actually appropriate needs immediate needs So this is an appropriate  appropriate funding for the Austin children for women and children Ill always support them You sa id number 18 right Number 18 has to do with increased mentoring is a no brainer Former teacher at ACC Austin independent school district And I taught also juniors in college But mentoring is very important to get the kids back on tra ck on education and the last item mayor And allow me to  Usa today good article about homeless veterans in Austin Texas Coming to Austin because he said he knows for a fact that there are more than 5000 homeless veterans in Austin Texas FYI I like to work with you and your office on that if it would be okay ',\n",
       " ' Thank you sir ']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now, remove strings said by a CCM or Mayor, i.e., those tagged with a name\n",
    "  \n",
    "# copy the list to a new list to not overwrite progress\n",
    "speaker_strings1 = speaker_strings  \n",
    "  \n",
    "# initializing substring\n",
    "# want this to be a string that IDs any alpha character + :\n",
    "subs = '\\w+:' \n",
    "  \n",
    "# using list comprehension to get string without substring  \n",
    "# I want to print all lists that DO NOT contain the substring\n",
    "#speaker_strings2 = [i for i in speaker_strings1 if not subs in i] \n",
    "speaker_strings2 = [string for string in speaker_strings1 if not re.search(subs, string)]\n",
    "\n",
    "speaker_strings2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, loop through all files to clean-- not ready for this yet\n",
    "##### better to do before or after splitting speakers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of all txt files, to run through loop later\n",
    "txt_list = glob(\"Austin_Transcripts/*.txt\")\n",
    "#txt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fileroot, fileext = os.path.splitext(pdffile)\n",
    "#output_filename = fileroot+'clean_.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_text in txt_list:\n",
    "    \n",
    "    # remove time stamp\n",
    "    text_cleaning = re.sub(\"[\\[].*?[\\]]\", \"\", content)\n",
    "\n",
    "    # remove the new line instances\n",
    "    text_cleaning = text_cleaning.replace(\"\\n\", \" \")\n",
    "\n",
    "    # subbing repeated white space for a single space\n",
    "    text_cleaning = re.sub('\\s\\s+', ' ', text_cleaning)\n",
    "\n",
    "    # remove header\n",
    "    text_cleaning = re.sub(r'.*====', '=', text_cleaning)\n",
    "\n",
    "    # try this tomorrow. this will get rid of more front matter\n",
    "    #text_cleaning = re.sub(r'.*Amen.', '=', text_cleaning)\n",
    "\n",
    "    # Remove all punctuation that is not \">\"\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\">\", \"\") # don't remove hyphens\n",
    "    remove = remove.replace(\":\", \"\") # keep these too, which helps me see when CC members are speaking\n",
    "    pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "    text_cleaning = re.sub(pattern, \"\", text_cleaning) \n",
    "\n",
    "    # Create an output file and put \"text\" in there\n",
    "    file = open(output_filename, \"w\")\n",
    "    file.write(text)\n",
    "    fileroot, fileext = os.path.splitext(pdffile)\n",
    "    output_filename = fileroot+'_clean.txt'\n",
    "    file.close()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing text files by individual, loop through all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic keyword maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The word_tokenize() function will break our text phrases into individual words\n",
    "text_ex = \n",
    "tokens = word_tokenize(text_ex)\n",
    "\n",
    "#we'll create a new list which contains punctuation we wish to clean\n",
    "punctuations = ['(',')',';',':','[',']',',']\n",
    "\n",
    "#We initialize the stopwords variable which is a list of words like #\"The\", \"I\", \"and\", etc. that don't hold much value as keywords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#We create a list comprehension which only returns a list of words #that are NOT IN stop_words and NOT IN punctuations.\n",
    "#keywords = [word for word in tokens if not word in stop_words and not word in punctuations]\n",
    "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
