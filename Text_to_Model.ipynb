{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile all .txt file data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all the files I want to grab\n",
    "cleantxt_list = glob.glob(\"Austin_Transcripts/*_c.txt\")\n",
    "\n",
    "# initiate a dictionary\n",
    "text_dict = {}\n",
    "\n",
    "# compile df - Jeremy magic\n",
    "date_list, text_list = list(), list()\n",
    "for filename in cleantxt_list:\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.read()\n",
    "    date = filename.split(\"/\")[1][:-6]\n",
    "    for element in data.split('_'):\n",
    "        text_list.append(element)\n",
    "        date_list.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dict = {'date': date_list, 'text': text_list}\n",
    "df = pd.DataFrame(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text\n",
       "0  2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...\n",
       "1  2015-03-26   There are 20 that are signed up for the next ...\n",
       "2  2015-03-26   Okay The other thing is Im going to do everyt...\n",
       "3  2015-03-26   Thanks Hello My name is Jacquie benastante an...\n",
       "4  2015-03-26   Good afternoon Three of us are here today and..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"speakers_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokeninze text column\n",
    "df['tokenized_sents'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "      <td>[Mayor, pro, tem, I, had, a, que, stion, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "      <td>[There, are, 20, that, are, signed, up, for, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "      <td>[Okay, The, other, thing, is, Im, going, to, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "      <td>[Thanks, Hello, My, name, is, Jacquie, benasta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "      <td>[Good, afternoon, Three, of, us, are, here, to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...   \n",
       "1  2015-03-26   There are 20 that are signed up for the next ...   \n",
       "2  2015-03-26   Okay The other thing is Im going to do everyt...   \n",
       "3  2015-03-26   Thanks Hello My name is Jacquie benastante an...   \n",
       "4  2015-03-26   Good afternoon Three of us are here today and...   \n",
       "\n",
       "                                     tokenized_sents  \n",
       "0  [Mayor, pro, tem, I, had, a, que, stion, for, ...  \n",
       "1  [There, are, 20, that, are, signed, up, for, t...  \n",
       "2  [Okay, The, other, thing, is, Im, going, to, d...  \n",
       "3  [Thanks, Hello, My, name, is, Jacquie, benasta...  \n",
       "4  [Good, afternoon, Three, of, us, are, here, to...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectors directly from the file\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Access vectors for specific words with a keyed lookup:\n",
    "vector = model['easy']\n",
    "# see the shape of the vector (300,)\n",
    "vector.shape\n",
    "# Processing sentences is not as simple as with Spacy:\n",
    "vectors = [model[x] for x in \"This is some text I am processing with Spacy\".split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "(\"'Word2VecKeyedVectors' object is not callable\", 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-de328bd688fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## add vectorized text column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectorized_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6012\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6013\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6014\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-de328bd688fd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## add vectorized text column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectorized_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: (\"'Word2VecKeyedVectors' object is not callable\", 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "## add vectorized text column \n",
    "df['vectorized_text'] = df.apply(lambda row: model(row['tokenized_sents']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>vectorized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "      <td>[Mayor, pro, tem, I, had, a, que, stion, for, ...</td>\n",
       "      <td>Word2Vec(vocab=22, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "      <td>[There, are, 20, that, are, signed, up, for, t...</td>\n",
       "      <td>Word2Vec(vocab=19, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "      <td>[Okay, The, other, thing, is, Im, going, to, d...</td>\n",
       "      <td>Word2Vec(vocab=15, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "      <td>[Thanks, Hello, My, name, is, Jacquie, benasta...</td>\n",
       "      <td>Word2Vec(vocab=26, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "      <td>[Good, afternoon, Three, of, us, are, here, to...</td>\n",
       "      <td>Word2Vec(vocab=20, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Ive been practicing in Austin Texas for 22 ye...</td>\n",
       "      <td>[Ive, been, practicing, in, Austin, Texas, for...</td>\n",
       "      <td>Word2Vec(vocab=22, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thank yo u city council This is my first time...</td>\n",
       "      <td>[Thank, yo, u, city, council, This, is, my, fi...</td>\n",
       "      <td>Word2Vec(vocab=21, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Floored is not natural anywhere on the body T...</td>\n",
       "      <td>[Floored, is, not, natural, anywhere, on, the,...</td>\n",
       "      <td>Word2Vec(vocab=21, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>So Dr Joan Sefcik indicates that fluoride is ...</td>\n",
       "      <td>[So, Dr, Joan, Sefcik, indicates, that, fluori...</td>\n",
       "      <td>Word2Vec(vocab=12, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thank you Okay Hi Okay I didnt have time or e...</td>\n",
       "      <td>[Thank, you, Okay, Hi, Okay, I, didnt, have, t...</td>\n",
       "      <td>Word2Vec(vocab=13, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thank you Im here today to expose to the worl...</td>\n",
       "      <td>[Thank, you, Im, here, today, to, expose, to, ...</td>\n",
       "      <td>Word2Vec(vocab=26, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay Okay I got discharged from St Davids hos...</td>\n",
       "      <td>[Okay, Okay, I, got, discharged, from, St, Dav...</td>\n",
       "      <td>Word2Vec(vocab=24, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>You guys  You guys have been very effective i...</td>\n",
       "      <td>[You, guys, You, guys, have, been, very, effec...</td>\n",
       "      <td>Word2Vec(vocab=26, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Our last expert is Dr Neil Car...</td>\n",
       "      <td>[Good, afternoon, Our, last, expert, is, Dr, N...</td>\n",
       "      <td>Word2Vec(vocab=24, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>As you can see this is not our personal opini...</td>\n",
       "      <td>[As, you, can, see, this, is, not, our, person...</td>\n",
       "      <td>Word2Vec(vocab=17, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I just want to be recognized fo...</td>\n",
       "      <td>[Mayor, pro, tem, I, just, want, to, be, recog...</td>\n",
       "      <td>Word2Vec(vocab=8, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon council My name is gust peña p...</td>\n",
       "      <td>[Good, afternoon, council, My, name, is, gust,...</td>\n",
       "      <td>Word2Vec(vocab=25, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>If I may you just indicated that well use our...</td>\n",
       "      <td>[If, I, may, you, just, indicated, that, well,...</td>\n",
       "      <td>Word2Vec(vocab=14, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>My only discussion is moms place is district ...</td>\n",
       "      <td>[My, only, discussion, is, moms, place, is, di...</td>\n",
       "      <td>Word2Vec(vocab=10, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem you might note for the audience...</td>\n",
       "      <td>[Mayor, pro, tem, you, might, note, for, the, ...</td>\n",
       "      <td>Word2Vec(vocab=12, size=100, alpha=0.025)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                               text  \\\n",
       "0   2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...   \n",
       "1   2015-03-26   There are 20 that are signed up for the next ...   \n",
       "2   2015-03-26   Okay The other thing is Im going to do everyt...   \n",
       "3   2015-03-26   Thanks Hello My name is Jacquie benastante an...   \n",
       "4   2015-03-26   Good afternoon Three of us are here today and...   \n",
       "5   2015-03-26   Ive been practicing in Austin Texas for 22 ye...   \n",
       "6   2015-03-26   Thank yo u city council This is my first time...   \n",
       "7   2015-03-26   Floored is not natural anywhere on the body T...   \n",
       "8   2015-03-26   So Dr Joan Sefcik indicates that fluoride is ...   \n",
       "9   2015-03-26   Thank you Okay Hi Okay I didnt have time or e...   \n",
       "10  2015-03-26   Thank you Im here today to expose to the worl...   \n",
       "11  2015-03-26   Okay Okay I got discharged from St Davids hos...   \n",
       "12  2015-03-26   You guys  You guys have been very effective i...   \n",
       "13  2015-03-26   Good afternoon Our last expert is Dr Neil Car...   \n",
       "14  2015-03-26   As you can see this is not our personal opini...   \n",
       "15  2015-03-26   Mayor pro tem I just want to be recognized fo...   \n",
       "16  2015-03-26   Good afternoon council My name is gust peña p...   \n",
       "17  2015-03-26   If I may you just indicated that well use our...   \n",
       "18  2015-03-26   My only discussion is moms place is district ...   \n",
       "19  2015-03-26   Mayor pro tem you might note for the audience...   \n",
       "\n",
       "                                      tokenized_sents  \\\n",
       "0   [Mayor, pro, tem, I, had, a, que, stion, for, ...   \n",
       "1   [There, are, 20, that, are, signed, up, for, t...   \n",
       "2   [Okay, The, other, thing, is, Im, going, to, d...   \n",
       "3   [Thanks, Hello, My, name, is, Jacquie, benasta...   \n",
       "4   [Good, afternoon, Three, of, us, are, here, to...   \n",
       "5   [Ive, been, practicing, in, Austin, Texas, for...   \n",
       "6   [Thank, yo, u, city, council, This, is, my, fi...   \n",
       "7   [Floored, is, not, natural, anywhere, on, the,...   \n",
       "8   [So, Dr, Joan, Sefcik, indicates, that, fluori...   \n",
       "9   [Thank, you, Okay, Hi, Okay, I, didnt, have, t...   \n",
       "10  [Thank, you, Im, here, today, to, expose, to, ...   \n",
       "11  [Okay, Okay, I, got, discharged, from, St, Dav...   \n",
       "12  [You, guys, You, guys, have, been, very, effec...   \n",
       "13  [Good, afternoon, Our, last, expert, is, Dr, N...   \n",
       "14  [As, you, can, see, this, is, not, our, person...   \n",
       "15  [Mayor, pro, tem, I, just, want, to, be, recog...   \n",
       "16  [Good, afternoon, council, My, name, is, gust,...   \n",
       "17  [If, I, may, you, just, indicated, that, well,...   \n",
       "18  [My, only, discussion, is, moms, place, is, di...   \n",
       "19  [Mayor, pro, tem, you, might, note, for, the, ...   \n",
       "\n",
       "                              vectorized_text  \n",
       "0   Word2Vec(vocab=22, size=100, alpha=0.025)  \n",
       "1   Word2Vec(vocab=19, size=100, alpha=0.025)  \n",
       "2   Word2Vec(vocab=15, size=100, alpha=0.025)  \n",
       "3   Word2Vec(vocab=26, size=100, alpha=0.025)  \n",
       "4   Word2Vec(vocab=20, size=100, alpha=0.025)  \n",
       "5   Word2Vec(vocab=22, size=100, alpha=0.025)  \n",
       "6   Word2Vec(vocab=21, size=100, alpha=0.025)  \n",
       "7   Word2Vec(vocab=21, size=100, alpha=0.025)  \n",
       "8   Word2Vec(vocab=12, size=100, alpha=0.025)  \n",
       "9   Word2Vec(vocab=13, size=100, alpha=0.025)  \n",
       "10  Word2Vec(vocab=26, size=100, alpha=0.025)  \n",
       "11  Word2Vec(vocab=24, size=100, alpha=0.025)  \n",
       "12  Word2Vec(vocab=26, size=100, alpha=0.025)  \n",
       "13  Word2Vec(vocab=24, size=100, alpha=0.025)  \n",
       "14  Word2Vec(vocab=17, size=100, alpha=0.025)  \n",
       "15   Word2Vec(vocab=8, size=100, alpha=0.025)  \n",
       "16  Word2Vec(vocab=25, size=100, alpha=0.025)  \n",
       "17  Word2Vec(vocab=14, size=100, alpha=0.025)  \n",
       "18  Word2Vec(vocab=10, size=100, alpha=0.025)  \n",
       "19  Word2Vec(vocab=12, size=100, alpha=0.025)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
