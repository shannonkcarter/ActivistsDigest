{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from pyemd import emd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile all .txt file data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all the files I want to grab\n",
    "cleantxt_list = glob.glob(\"Austin_Transcripts/*_c.txt\")\n",
    "\n",
    "# initiate a dictionary\n",
    "text_dict = {}\n",
    "\n",
    "# compile df - Jeremy magic\n",
    "date_list, text_list = list(), list()\n",
    "for filename in cleantxt_list:\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.read()\n",
    "    date = filename.split(\"/\")[1][:-6]\n",
    "    for element in data.split('_'):\n",
    "        text_list.append(element)\n",
    "        date_list.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dict = {'date': date_list, 'text': text_list}\n",
    "df = pd.DataFrame(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text\n",
       "0  2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...\n",
       "1  2015-03-26   There are 20 that are signed up for the next ...\n",
       "2  2015-03-26   Okay The other thing is Im going to do everyt...\n",
       "3  2015-03-26   Thanks Hello My name is Jacquie benastante an...\n",
       "4  2015-03-26   Good afternoon Three of us are here today and..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"speakers_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokeninze text column\n",
    "df['tokenized_text'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "      <td>[Mayor, pro, tem, I, had, a, que, stion, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "      <td>[There, are, 20, that, are, signed, up, for, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "      <td>[Okay, The, other, thing, is, Im, going, to, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "      <td>[Thanks, Hello, My, name, is, Jacquie, benasta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "      <td>[Good, afternoon, Three, of, us, are, here, to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...   \n",
       "1  2015-03-26   There are 20 that are signed up for the next ...   \n",
       "2  2015-03-26   Okay The other thing is Im going to do everyt...   \n",
       "3  2015-03-26   Thanks Hello My name is Jacquie benastante an...   \n",
       "4  2015-03-26   Good afternoon Three of us are here today and...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [Mayor, pro, tem, I, had, a, que, stion, for, ...  \n",
       "1  [There, are, 20, that, are, signed, up, for, t...  \n",
       "2  [Okay, The, other, thing, is, Im, going, to, d...  \n",
       "3  [Thanks, Hello, My, name, is, Jacquie, benasta...  \n",
       "4  [Good, afternoon, Three, of, us, are, here, to...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pre-trained Google News model\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "emb_model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a function that will convert lists to vectors\n",
    "def get_vectors(list): \n",
    "  #For word in list, get embedding, return all words in list\n",
    "  vectors = []\n",
    "  for word in list: \n",
    "    try:\n",
    "      vector = emb_model[word]\n",
    "      vectors.append(vector)\n",
    "\n",
    "    except KeyError: \n",
    "      pass\n",
    "\n",
    "  return vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the function to the tokenized text, i.e., tokenized text to vectorized text\n",
    "df['vectors'] = df[\"tokenized_text\"].apply(get_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "      <td>[Mayor, pro, tem, I, had, a, que, stion, for, ...</td>\n",
       "      <td>[[-0.07763672, -0.12792969, 0.103515625, -0.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "      <td>[There, are, 20, that, are, signed, up, for, t...</td>\n",
       "      <td>[[-0.111328125, 0.14355469, 0.18945312, -0.161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "      <td>[Okay, The, other, thing, is, Im, going, to, d...</td>\n",
       "      <td>[[0.09375, -0.07470703, 0.2109375, 0.22167969,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "      <td>[Thanks, Hello, My, name, is, Jacquie, benasta...</td>\n",
       "      <td>[[-0.3046875, 0.20703125, -0.00390625, 0.16503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "      <td>[Good, afternoon, Three, of, us, are, here, to...</td>\n",
       "      <td>[[-0.10888672, -0.07470703, -0.045410156, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...   \n",
       "1  2015-03-26   There are 20 that are signed up for the next ...   \n",
       "2  2015-03-26   Okay The other thing is Im going to do everyt...   \n",
       "3  2015-03-26   Thanks Hello My name is Jacquie benastante an...   \n",
       "4  2015-03-26   Good afternoon Three of us are here today and...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [Mayor, pro, tem, I, had, a, que, stion, for, ...   \n",
       "1  [There, are, 20, that, are, signed, up, for, t...   \n",
       "2  [Okay, The, other, thing, is, Im, going, to, d...   \n",
       "3  [Thanks, Hello, My, name, is, Jacquie, benasta...   \n",
       "4  [Good, afternoon, Three, of, us, are, here, to...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [[-0.07763672, -0.12792969, 0.103515625, -0.33...  \n",
       "1  [[-0.111328125, 0.14355469, 0.18945312, -0.161...  \n",
       "2  [[0.09375, -0.07470703, 0.2109375, 0.22167969,...  \n",
       "3  [[-0.3046875, 0.20703125, -0.00390625, 0.16503...  \n",
       "4  [[-0.10888672, -0.07470703, -0.045410156, -0.0...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize vectors\n",
    "#### Above, we have one vector per word stored in an array. we need to average these so we have one vector per row/sentence/utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to sum vectors\n",
    "def sum_vectors(vector_list):\n",
    "    return np.sum(vector_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to column \"vectors\"\n",
    "df['vector_sum'] = df[\"vectors\"].apply(sum_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to count the length of the vector (roughly how many word in that sentence/utterance)\n",
    "def list_length(vector_list):\n",
    "    return len(vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to column vectors and make the output a column\n",
    "df[\"vector_length\"] = df[\"vectors\"].apply(list_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average by dividing sum by length\n",
    "df[\"vector_average\"] = df[\"vector_sum\"]/df[\"vector_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>vectors</th>\n",
       "      <th>vector_sum</th>\n",
       "      <th>vector_length</th>\n",
       "      <th>vector_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Mayor pro tem I had a que stion for Mr Mckinn...</td>\n",
       "      <td>[Mayor, pro, tem, I, had, a, que, stion, for, ...</td>\n",
       "      <td>[[-0.07763672, -0.12792969, 0.103515625, -0.33...</td>\n",
       "      <td>[3.370697, 2.1581726, 2.4202385, 9.209576, -5....</td>\n",
       "      <td>100</td>\n",
       "      <td>[0.03370697, 0.021581726, 0.024202384, 0.09209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>There are 20 that are signed up for the next ...</td>\n",
       "      <td>[There, are, 20, that, are, signed, up, for, t...</td>\n",
       "      <td>[[-0.111328125, 0.14355469, 0.18945312, -0.161...</td>\n",
       "      <td>[2.2872353, 3.21389, 0.009590149, 9.508865, -8...</td>\n",
       "      <td>94</td>\n",
       "      <td>[0.02433229, 0.03419032, 0.00010202286, 0.1011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Okay The other thing is Im going to do everyt...</td>\n",
       "      <td>[Okay, The, other, thing, is, Im, going, to, d...</td>\n",
       "      <td>[[0.09375, -0.07470703, 0.2109375, 0.22167969,...</td>\n",
       "      <td>[2.133606, 1.0718994, 1.0830688, 6.748413, -4....</td>\n",
       "      <td>51</td>\n",
       "      <td>[0.041835412, 0.021017635, 0.021236643, 0.1323...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Thanks Hello My name is Jacquie benastante an...</td>\n",
       "      <td>[Thanks, Hello, My, name, is, Jacquie, benasta...</td>\n",
       "      <td>[[-0.3046875, 0.20703125, -0.00390625, 0.16503...</td>\n",
       "      <td>[5.8538156, 13.34121, 12.888611, 41.340435, -3...</td>\n",
       "      <td>470</td>\n",
       "      <td>[0.012454927, 0.028385554, 0.027422577, 0.0879...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Good afternoon Three of us are here today and...</td>\n",
       "      <td>[Good, afternoon, Three, of, us, are, here, to...</td>\n",
       "      <td>[[-0.10888672, -0.07470703, -0.045410156, -0.0...</td>\n",
       "      <td>[-1.589881, 2.285658, 3.9089699, 5.8369904, -4...</td>\n",
       "      <td>84</td>\n",
       "      <td>[-0.018927153, 0.027210213, 0.046535354, 0.069...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2015-03-26   Mayor pro tem I had a que stion for Mr Mckinn...   \n",
       "1  2015-03-26   There are 20 that are signed up for the next ...   \n",
       "2  2015-03-26   Okay The other thing is Im going to do everyt...   \n",
       "3  2015-03-26   Thanks Hello My name is Jacquie benastante an...   \n",
       "4  2015-03-26   Good afternoon Three of us are here today and...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [Mayor, pro, tem, I, had, a, que, stion, for, ...   \n",
       "1  [There, are, 20, that, are, signed, up, for, t...   \n",
       "2  [Okay, The, other, thing, is, Im, going, to, d...   \n",
       "3  [Thanks, Hello, My, name, is, Jacquie, benasta...   \n",
       "4  [Good, afternoon, Three, of, us, are, here, to...   \n",
       "\n",
       "                                             vectors  \\\n",
       "0  [[-0.07763672, -0.12792969, 0.103515625, -0.33...   \n",
       "1  [[-0.111328125, 0.14355469, 0.18945312, -0.161...   \n",
       "2  [[0.09375, -0.07470703, 0.2109375, 0.22167969,...   \n",
       "3  [[-0.3046875, 0.20703125, -0.00390625, 0.16503...   \n",
       "4  [[-0.10888672, -0.07470703, -0.045410156, -0.0...   \n",
       "\n",
       "                                          vector_sum  vector_length  \\\n",
       "0  [3.370697, 2.1581726, 2.4202385, 9.209576, -5....            100   \n",
       "1  [2.2872353, 3.21389, 0.009590149, 9.508865, -8...             94   \n",
       "2  [2.133606, 1.0718994, 1.0830688, 6.748413, -4....             51   \n",
       "3  [5.8538156, 13.34121, 12.888611, 41.340435, -3...            470   \n",
       "4  [-1.589881, 2.285658, 3.9089699, 5.8369904, -4...             84   \n",
       "\n",
       "                                      vector_average  \n",
       "0  [0.03370697, 0.021581726, 0.024202384, 0.09209...  \n",
       "1  [0.02433229, 0.03419032, 0.00010202286, 0.1011...  \n",
       "2  [0.041835412, 0.021017635, 0.021236643, 0.1323...  \n",
       "3  [0.012454927, 0.028385554, 0.027422577, 0.0879...  \n",
       "4  [-0.018927153, 0.027210213, 0.046535354, 0.069...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['vector_average'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activistsdigest():\n",
    "    # accept user input\n",
    "    text = input(\"Write a topic of interest here: \")\n",
    "\n",
    "    # clean and tokenize user input\n",
    "    tokenized_input = nltk.word_tokenize(text)\n",
    "    \n",
    "    # get vectors for input text\n",
    "    filename = 'GoogleNews-vectors-negative300.bin'\n",
    "    emb_model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "    vectorized_input = emb_model[tokenized_input]\n",
    "\n",
    "    # calculate WMD distance\n",
    "    input_veclist = []\n",
    "    for i in df['vector_average']:\n",
    "        distance = emb_model.wmdistance(i, vectorized_input)\n",
    "        input_veclist.append(distance)\n",
    "\n",
    "    # add input_veclist to df\n",
    "    df['inputvectors'] = input_veclist\n",
    "\n",
    "    # sort dataframe in ascending order by distance\n",
    "    df.sort_values(by=['distance'])\n",
    "\n",
    "    # return url for top 3 rows\n",
    "    return print(df['text'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write a topic of interest here:  bike\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-05bc2236e21e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactivistsdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-b99445b9739b>\u001b[0m in \u001b[0;36mactivistsdigest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minput_veclist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector_average'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwmdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0minput_veclist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mwmdistance\u001b[0;34m(self, document1, document2)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mlen_pre_oov2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mdocument1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mdocument2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mdiff1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_pre_oov1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mdiff2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_pre_oov2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mlen_pre_oov2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mdocument1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mdocument2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mdiff1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_pre_oov1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mdiff2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_pre_oov2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "activistsdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bike']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"bike\"\n",
    "\n",
    "# clean and tokenize user input\n",
    "tokenized_input = nltk.word_tokenize(text)\n",
    "\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_input = emb_model[tokenized_input]\n",
    "#vectorized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. check_pairwise_arrays expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3a073dd744d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector_average'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvectorized_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#cos_sim = dot(i, vectorized_input)/(norm(i)*norm(vectorized_input))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m                         estimator=estimator)\n\u001b[1;32m    113\u001b[0m         Y = check_array(Y, accept_sparse='csr', dtype=dtype,\n\u001b[0;32m--> 114\u001b[0;31m                         estimator=estimator)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprecomputed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 539\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. check_pairwise_arrays expected <= 2."
     ]
    }
   ],
   "source": [
    "# calculate WMD distance\n",
    "input_veclist = []\n",
    "for i in df['vector_average']:\n",
    "    \n",
    "    cos_sim = cosine_similarity([i], [vectorized_input])\n",
    "    \n",
    "    #cos_sim = dot(i, vectorized_input)/(norm(i)*norm(vectorized_input))\n",
    "    input_veclist.append(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean it up and pickle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the process columns. Only need vector_average and the identifiers\n",
    "df_clean = df.drop(['tokenized_text', 'vectors', 'vector_sum', 'vector_length'], axis=1)\n",
    "#df_clean.head()\n",
    "df_clean.to_csv(\"normalized_vectorized_speakers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_pickle(\"pickleddf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word2VecKeyedVectors' object has no attribute 'to_pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d1ac81ecc29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pickledmodel.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Word2VecKeyedVectors' object has no attribute 'to_pickle'"
     ]
    }
   ],
   "source": [
    "emb_model.to_pickle(\"pickledmodel.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
