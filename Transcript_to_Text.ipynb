{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 \n",
    "import textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import nltk\n",
    "import glob\n",
    "#from glob import glob\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kathrynkundrod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kathrynkundrod/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture text from pdf files, a singular example\n",
    "https://medium.com/@rqaiserr/how-to-convert-pdfs-into-searchable-key-words-with-python-85aab86c544f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = \"Austin_Transcripts/scrape2/2015_01_29.pdf\"\n",
    "\n",
    "pdfFileObj = open(filename,'rb')\n",
    "\n",
    "#The pdfReader variable is a readable object that will be parsed\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "#discerning the number of pages will allow us to parse through all #the pages\n",
    "num_pages = pdfReader.numPages\n",
    "count = 0\n",
    "text = \"\"\n",
    "\n",
    "#The while loop will read each page\n",
    "while count < num_pages:\n",
    "    pageObj = pdfReader.getPage(count)\n",
    "    count +=1\n",
    "    text += pageObj.extractText()\n",
    "\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture text from pdf files, loop through all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'glob' files, i.e., make a list of all with the same desired attribute\n",
    "# in this case, all pdfs in the folder Austin_Transcripts\n",
    "filelist = glob.glob(\"Austin_Transcripts/*.pdf\")\n",
    "#filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-3fb35bac2c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpageObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdfReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpageObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Create an output file and put \"text\" in there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PyPDF2/pdf.py\u001b[0m in \u001b[0;36mextractText\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2593\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/Contents\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContentStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2595\u001b[0;31m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContentStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2596\u001b[0m         \u001b[0;31m# Note: we check all strings are TextStringObjects.  ByteStringObjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0;31m# are strings where the byte->string encoding was unknown, so adding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PyPDF2/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream, pdf)\u001b[0m\n\u001b[1;32m   2672\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__parseContentStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__parseContentStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PyPDF2/pdf.py\u001b[0m in \u001b[0;36m__parseContentStream\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   2704\u001b[0m                     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2706\u001b[0;31m                 \u001b[0moperands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_readInlineImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PyPDF2/generic.py\u001b[0m in \u001b[0;36mreadObject\u001b[0;34m(stream, pdf)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# array object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mArrayObject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadFromStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# boolean object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PyPDF2/generic.py\u001b[0m in \u001b[0;36mreadFromStream\u001b[0;34m(stream, pdf)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# read and append obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mreadFromStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadFromStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PyPDF2/generic.py\u001b[0m in \u001b[0;36mreadObject\u001b[0;34m(stream, pdf)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndirectObject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadFromStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mNumberObject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadFromStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PyPDF2/generic.py\u001b[0m in \u001b[0;36mreadFromStream\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mFloatObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mNumberObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0mreadFromStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadFromStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PyPDF2/generic.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mByteDot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for each file in filelist...\n",
    "for pdffile in filelist:\n",
    "    \n",
    "    # Open the pdf file and make it a pdf object\n",
    "    pdfFileObj = open(pdffile,'rb')\n",
    "\n",
    "    # The pdfReader variable is a readable object that will be parsed\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "    # Discerning the number of pages will allow us to parse through all #the pages\n",
    "    num_pages = pdfReader.numPages\n",
    "    count = 0\n",
    "    text = \"\"\n",
    "\n",
    "    # This while loop will read each page\n",
    "    # The 'text' output is what we want to save for each pdf\n",
    "    while count < num_pages:\n",
    "        pageObj = pdfReader.getPage(count)\n",
    "        count +=1\n",
    "        text += pageObj.extractText()\n",
    "\n",
    "    # Create an output file and put \"text\" in there\n",
    "    file = open(output_filename, \"w\")\n",
    "    file.write(text)\n",
    "    fileroot, fileext = os.path.splitext(pdffile)\n",
    "    output_filename = fileroot+'.txt'\n",
    "    file.close()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text files, a singular example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the file before opening so it's easier to iterate on later\n",
    "text_ex =  \"Austin_Transcripts/2017_03_23.txt\"\n",
    "f = open(text_ex, 'r')\n",
    "\n",
    "# turns f file into a string\n",
    "content = f.read()\n",
    "#type(content)   # it's a string\n",
    "#print(content)  # see, it's a string\n",
    "\n",
    "# always close files after pulling out the \"content\" or whatever you want to avoid overwriting\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic text cleanup\n",
    "\n",
    "# remove time stamp\n",
    "# this re command removes everything between \"[]\"\n",
    "text_cleaning = re.sub(\"[\\[].*?[\\]]\", \"\", content)\n",
    "\n",
    "# remove the new line instances\n",
    "text_cleaning = text_cleaning.replace(\"\\n\", \" \")\n",
    "\n",
    "# subbing repeated white space for a single space\n",
    "text_cleaning = re.sub('\\s\\s+', ' ', text_cleaning)\n",
    "\n",
    "# remove header\n",
    "text_cleaning = re.sub(r'.*====', '=', text_cleaning)\n",
    "\n",
    "# remove all punctuation that is not \">\" or \":\"\n",
    "# we need these puncts to parse speakers\n",
    "remove = string.punctuation\n",
    "remove = remove.replace(\">\", \"\") # don't remove carats\n",
    "remove = remove.replace(\":\", \"\") # keep these too, which helps me see when CC members are speaking\n",
    "pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "text_cleaning = re.sub(pattern, \"\", text_cleaning) \n",
    "\n",
    "## Split text by speaker. Each \">>\" indicates a new speaker\n",
    "# split by speakers - now I have a list of string, each string a new speaker\n",
    "speaker_strings = text_cleaning.split(\">>\")\n",
    "speaker_strings[10:20]\n",
    "#type(speaker_strings)\n",
    "\n",
    "## Now, remove strings said by a CCM or Mayor, i.e., those tagged with a name  \n",
    "# initializing substring\n",
    "# want to recognize [any alpha character + :]\n",
    "subs = '\\w+:' # \"\\w\" indicates any alpha character \n",
    "  \n",
    "# using list comprehension to return strings without the substring above\n",
    "# I want to print all lists that DO NOT contain the substring\n",
    "#speaker_strings2 = [i for i in speaker_strings1 if not subs in i] \n",
    "speaker_strings = [string for string in speaker_strings if not re.search(subs, string)]\n",
    "\n",
    "# now, same thing to remove the prayer\n",
    "subs2 = \"Amen\"\n",
    "speaker_strings = [string for string in speaker_strings if not re.search(subs2, string)]\n",
    "\n",
    "speaker_strings_long = []\n",
    "for list_element in speaker_strings:\n",
    "    if len(list_element) >= 100:\n",
    "        speaker_strings_long.append(list_element)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# concatenate into a string for eventual export\n",
    "speaker_strings_long = '_'.join(speaker_strings_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, loop through all files to clean and parse by speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Austin_Transcripts/2015-02-26.txt',\n",
       " 'Austin_Transcripts/2015-03-26.txt',\n",
       " 'Austin_Transcripts/2015-04-23.txt',\n",
       " 'Austin_Transcripts/2015-05-21.txt',\n",
       " 'Austin_Transcripts/2015-06-18.txt',\n",
       " 'Austin_Transcripts/2015-08-20.txt',\n",
       " 'Austin_Transcripts/2015-09-17.txt',\n",
       " 'Austin_Transcripts/2015-10-15.txt',\n",
       " 'Austin_Transcripts/2015-11-19.txt',\n",
       " 'Austin_Transcripts/2015-12-17.txt',\n",
       " 'Austin_Transcripts/2016-01-28.txt',\n",
       " 'Austin_Transcripts/2016-02-25.txt',\n",
       " 'Austin_Transcripts/2016-03-24.txt',\n",
       " 'Austin_Transcripts/2016-04-21.txt',\n",
       " 'Austin_Transcripts/2016-05-19.txt',\n",
       " 'Austin_Transcripts/2016-06-23.txt',\n",
       " 'Austin_Transcripts/2016-08-18.txt',\n",
       " 'Austin_Transcripts/2016-09-22.txt',\n",
       " 'Austin_Transcripts/2016-10-20.txt',\n",
       " 'Austin_Transcripts/2016-11-10.txt',\n",
       " 'Austin_Transcripts/2016-12-08.txt',\n",
       " 'Austin_Transcripts/2016-12-15.txt',\n",
       " 'Austin_Transcripts/2017-02-16.txt',\n",
       " 'Austin_Transcripts/2017-03_23.txt',\n",
       " 'Austin_Transcripts/2017-04-13.txt',\n",
       " 'Austin_Transcripts/2017-05-18.txt',\n",
       " 'Austin_Transcripts/2017-06-15.txt',\n",
       " 'Austin_Transcripts/2017-06-22.txt',\n",
       " 'Austin_Transcripts/2017-08-17.txt',\n",
       " 'Austin_Transcripts/2017-08-31.txt',\n",
       " 'Austin_Transcripts/2017-09-28.txt',\n",
       " 'Austin_Transcripts/2017-10-19.txt',\n",
       " 'Austin_Transcripts/2017-11-09.txt',\n",
       " 'Austin_Transcripts/2017-12-14.txt',\n",
       " 'Austin_Transcripts/2018-02-15.txt',\n",
       " 'Austin_Transcripts/2018-03-22.txt',\n",
       " 'Austin_Transcripts/2018-04-26.txt',\n",
       " 'Austin_Transcripts/2018-05-24.txt',\n",
       " 'Austin_Transcripts/2018-06-28.txt',\n",
       " 'Austin_Transcripts/2018-08-30.txt',\n",
       " 'Austin_Transcripts/2018_08_30.txt',\n",
       " 'Austin_Transcripts/2018_09_20.txt',\n",
       " 'Austin_Transcripts/2018_10_18.txt',\n",
       " 'Austin_Transcripts/2018_11_29.txt',\n",
       " 'Austin_Transcripts/2018_12_13.txt',\n",
       " 'Austin_Transcripts/2019-02-07.txt',\n",
       " 'Austin_Transcripts/2019-02-21.txt',\n",
       " 'Austin_Transcripts/2019-03-07.txt',\n",
       " 'Austin_Transcripts/2019-03-28.txt',\n",
       " 'Austin_Transcripts/2019-04-11.txt',\n",
       " 'Austin_Transcripts/2019-04-25.txt',\n",
       " 'Austin_Transcripts/2019-05-09.txt',\n",
       " 'Austin_Transcripts/2019-05-23.txt',\n",
       " 'Austin_Transcripts/2019-06-06.txt',\n",
       " 'Austin_Transcripts/2019-06-20.txt',\n",
       " 'Austin_Transcripts/2019-08-08.txt',\n",
       " 'Austin_Transcripts/2019-08-22.txt',\n",
       " 'Austin_Transcripts/2019-09-10.txt']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a list of all txt files, to run through loop later\n",
    "txt_list = glob.glob(\"Austin_Transcripts/*.txt\")\n",
    "txt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fileroot, fileext = os.path.splitext(raw_text)\n",
    "#output_filename = fileroot+'clean_.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_text in txt_list:\n",
    "    \n",
    "    f = open(raw_text,'r')\n",
    "\n",
    "    # turns f file into a string\n",
    "    content = f.read()\n",
    "    \n",
    "    # always close files after pulling out the \"content\" or whatever you want to avoid overwriting\n",
    "    f.close()\n",
    "    \n",
    "    # basic text cleaning\n",
    "    text_cleaning = re.sub(\"[\\[].*?[\\]]\", \"\", content)\n",
    "    text_cleaning = text_cleaning.replace(\"\\n\", \" \")\n",
    "    text_cleaning = re.sub('\\s\\s+', ' ', text_cleaning)\n",
    "    text_cleaning = re.sub(r'.*====', '=', text_cleaning)\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\">\", \"\") # don't remove carats\n",
    "    remove = remove.replace(\":\", \"\") # keep these too, which helps me see when CC members are speaking\n",
    "    pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "    text_cleaning = re.sub(pattern, \"\", text_cleaning) \n",
    "\n",
    "    # separate speakers\n",
    "    speaker_strings = text_cleaning.split(\">>\")\n",
    "    \n",
    "    ## Now, remove strings said by a CCM or Mayor, i.e., those tagged with a name  \n",
    "    # initializing substring\n",
    "    # want to recognize [any alpha character + :]\n",
    "    subs = '\\w+:' # \"\\w\" indicates any alpha character \n",
    "\n",
    "    # using list comprehension to return strings without the substring above\n",
    "    # I want to print all lists that DO NOT contain the substring\n",
    "    #speaker_strings2 = [i for i in speaker_strings1 if not subs in i] \n",
    "    speaker_strings = [string for string in speaker_strings if not re.search(subs, string)]\n",
    "\n",
    "    # now, same thing to remove the prayer\n",
    "    subs2 = \"Amen\"\n",
    "    speaker_strings = [string for string in speaker_strings if not re.search(subs2, string)]\n",
    "\n",
    "    speaker_strings_long = []\n",
    "    for list_element in speaker_strings:\n",
    "        if len(list_element) >= 100:\n",
    "            speaker_strings_long.append(list_element)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Put it in a string for export\n",
    "    speaker_strings_long = '_'.join(speaker_strings_long)\n",
    "\n",
    "    # Create an output file and put \"text\" in there\n",
    "    file = open(output_filename, \"w\")\n",
    "    file.write(speaker_strings_long)\n",
    "    #fileroot, fileext = os.path.splitext(raw_text)\n",
    "    output_filename = raw_text+'_clean.txt'\n",
    "    file.close()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile all .txt file data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantxt_list = glob.glob(\"Austin_Transcripts/*_clean.txt\")\n",
    "text_dict = {}\n",
    "date_list, text_list = list(), list()\n",
    "for filename in cleantxt_list:\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.read()\n",
    "    date = filename.split(\"/\")[1][:-10]\n",
    "    for element in data.split('_'):\n",
    "        text_list.append(element)\n",
    "        date_list.append(date)\n",
    "    #key = filename.split(\"/\")[1]\n",
    "    #date_list.append(key[:-10])\n",
    "    #text_list.append(data)\n",
    "    #text_dict[key[:-10]] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(data.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019_08_08_'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename.split('/')[1][:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dict = {'date': date_list, 'text': text_list}\n",
    "df = pd.DataFrame(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_01_29</td>\n",
       "      <td>Okay and 14 14 is the relocation assistance a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_01_29</td>\n",
       "      <td>17 Okay yes 17 appropriating 170000 grant fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_01_29</td>\n",
       "      <td>Thank you may you mayor pro tem and councilme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_01_29</td>\n",
       "      <td>They very quickly will do this Theyll take th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_01_29</td>\n",
       "      <td>Thank you members Matthew assistant attorney ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text\n",
       "0  2015_01_29   Okay and 14 14 is the relocation assistance a...\n",
       "1  2015_01_29   17 Okay yes 17 appropriating 170000 grant fun...\n",
       "2  2015_01_29   Thank you may you mayor pro tem and councilme...\n",
       "3  2015_01_29   They very quickly will do this Theyll take th...\n",
       "4  2015_01_29   Thank you members Matthew assistant attorney ..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13509, 2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015_01_29', '2015_02_26']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(text_dict.keys())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_dict['2015_01_29'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
